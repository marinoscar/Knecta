# Spreadsheet Agent — Outstanding Issues

**Date**: 2026-02-23
**Project**: 362508ab (FP&A)
**Runs investigated**: 2a497450 (review_pending), c8c8af1f (completed but broken)

---

## Issue 1: Progress Bar Not Shown During Streaming

**Severity**: High (UX)
**Screenshots**: #1 (no progress bar while streaming), #2 (bar appears only at end)

### Root Cause

The `useSpreadsheetRun` hook checks `event.progress` (a nested property) to set the progress state:

```typescript
// useSpreadsheetRun.ts:117
if (event.type === 'progress' && event.progress) {
  setProgress(event.progress);
}
```

But the backend emits progress data **flat on the event object**, not nested under a `progress` key:

```typescript
// ingest.ts:27 (and similar in extract.ts, persist.ts)
emit({
  type: 'progress',
  completedFiles: fileInventory.length,
  totalFiles: files.length,
  percentComplete: 20,
  // NO "progress" nested key
});
```

So `event.progress` is always `undefined` during streaming → `setProgress()` is never called → the `LinearProgress` bar (which renders only when `progress` is truthy) never appears.

The progress bar appears at the very end only because `fetchRun()` is called after `run_complete`/`review_ready`, and the run's `progress` JSON field in the DB is set by `updateRunProgress()` which stores the flat event object. When `fetchRun` returns the run, `run.progress` exists and is a valid object.

### Fix Required

**Option A (Recommended)**: Fix the hook to read progress fields directly from the event:

```typescript
if (event.type === 'progress') {
  setProgress({
    percentComplete: event.percentComplete as number ?? 0,
    message: event.message as string ?? 'Processing...',
    // map other fields as needed
  });
}
```

**Option B**: Fix the backend to wrap progress data in a nested `progress` key:

```typescript
emit({ type: 'progress', progress: { percentComplete: 20, ... } });
```

Option A is safer (doesn't change the backend event format that's already persisted in the DB).

### Files to Change

- `apps/web/src/hooks/useSpreadsheetRun.ts:117-119`

---

## Issue 2: Token Count 0 on Resume After Review

**Severity**: Medium (UX)

### Root Cause

When the agent resumes after plan approval, it skips the analyze and design phases (which are the only LLM-calling phases). The extract/validate/persist phases don't use the LLM, so `tokensUsed` stays at `{0, 0, 0}` in state.

The token state in LangGraph uses a **reducer** that accumulates:

```typescript
tokensUsed: Annotation<TokenUsage>({
  reducer: (prev, next) => ({
    prompt: prev.prompt + next.prompt,
    completion: prev.completion + next.completion,
    total: prev.total + next.total,
  }),
  default: () => ({ prompt: 0, completion: 0, total: 0 }),
}),
```

But on resume, the initial state doesn't carry forward the tokens from the previous run. The run's `stats.tokensUsed` from the first execution (analyze+design) is `{total: 73540}` but it's not injected into the initial state on resume.

### Evidence from DB

Run `c8c8af1f`:
- Stats from first execution pause: `tokensUsed: { total: 73540 }` (from run `2a497450`)
- Stats after completion: `tokensUsed: { total: 0 }` (new run `c8c8af1f` didn't accumulate)

Note: The user also created **new runs** instead of approving existing ones (see Issue 5), which means tokens from the first run were completely lost.

### Fix Required

When resuming after review, inject the previous run's token usage into the initial state:

```typescript
if (isResumeAfterReview && run.stats?.tokensUsed) {
  initialState.tokensUsed = run.stats.tokensUsed;
}
```

### Files to Change

- `apps/api/src/spreadsheet-agent/agent/spreadsheet-agent-agent.service.ts:125-190`

---

## Issue 3: LLM Hallucinating File IDs → Persist Node Fails Silently

**Severity**: Critical (Data Loss)
**Screenshot**: #6 (shows "Agent completed successfully" but 0 tables, 0 rows)

### Root Cause

The extraction plan generated by the LLM in the **design node** includes `sourceFileId` for each table. However, the LLM **does not have access to the actual file UUIDs** from the database. The sheet analysis data passed to the design prompt includes `fileId` and `fileName`, but the LLM fabricates/guesses the file IDs.

**Evidence from DB**:

```
Plan sourceFileIds: ['362508ab-3330-4063-a320-912dc804139d']  ← This is the PROJECT ID, not a file ID
Actual file IDs: [
  { id: '0968cd92-...', name: 'Sample1.xls' },
  { id: '3062b195-...', name: 'Sample2.xls' }
]
```

The LLM used the project ID as the `sourceFileId` for ALL 23 tables because the project ID was mentioned in the prompt (`Project ID: ${projectId}`).

When the **persist node** tries to create `SpreadsheetTable` records, it uses:

```typescript
// persist.ts:31
await prisma.spreadsheetTable.create({
  data: {
    projectId,
    fileId: planTable?.sourceFileId || '',  // ← FK to spreadsheet_files.id
    ...
  },
});
```

This fails with a FK constraint violation because `362508ab-...` is not a valid `spreadsheet_files.id`. The error is caught by the try/catch in persist node and returned as `{ error: 'Persist failed: ...' }` — but this sets `state.error` rather than throwing, so the graph completes "successfully".

The **agent service** then sees no exception from `graph.invoke()` and marks the run as `completed` with `tablesExtracted: 23` (from the mock extraction results), even though 0 tables were actually persisted.

### Why It's Silent

1. The persist node catches errors and returns a state update with `error` field, but doesn't throw
2. The agent service checks `finalState.extractionResults?.length` (which is 23 mock results), not whether tables were actually written to DB
3. No validation that `sourceFileId` values in the plan correspond to real file records

### Fix Required (Multi-Part)

**Part A — Don't use LLM-generated file IDs**:

The `sourceFileId` in the extraction plan should be set **programmatically** from the actual `SheetAnalysis.fileId` values (which come from real DB records via ingest), NOT from the LLM output. The LLM should only generate the schema design (table names, columns, types, transformations).

In the design node, after the LLM produces the plan, replace `sourceFileId` with the correct value looked up from `sheetAnalyses`:

```typescript
// After LLM generates the plan, fix up file IDs
for (const table of result.tables) {
  const analysis = sheetAnalyses.find(a =>
    a.fileName === table.sourceFileName && a.sheetName === table.sourceSheetName
  );
  if (analysis) {
    table.sourceFileId = analysis.fileId;
  }
}
```

**Part B — Persist node should throw on failure**:

If the persist node fails to create table records, it should throw an error that propagates to the agent service, not silently return a state error. Or at minimum, the agent service should check `finalState.error` before marking the run as completed.

**Part C — Agent service should validate final state**:

```typescript
if (finalState.error) {
  // Mark run as failed, not completed
  await this.spreadsheetAgentService.updateRunStatus(runId, 'failed', {
    errorMessage: finalState.error,
    completedAt: new Date(),
  });
}
```

### Files to Change

- `apps/api/src/spreadsheet-agent/agent/nodes/design.ts` — Fix up sourceFileId after LLM output
- `apps/api/src/spreadsheet-agent/agent/nodes/persist.ts` — Throw on failure or report properly
- `apps/api/src/spreadsheet-agent/agent/spreadsheet-agent-agent.service.ts` — Check `finalState.error`
- Consider removing `sourceFileId` from the LLM Zod schema entirely and adding it programmatically

---

## Issue 4: "Start Run" Creates New Run Instead of Resuming Approved Run

**Severity**: High (UX/Token Waste)
**Screenshots**: #4 (agent re-runs analyze+design after "approval")

### Root Cause

When the user sees the extraction plan review and the "Start Run" button is also visible, they may click "Start Run" instead of "Approve Plan". This creates a **brand new run** that starts from scratch (ingest → analyze → design), wasting LLM tokens.

**Evidence from logs**:

The project had multiple runs:
- `2a497450` — first run, paused at review_pending, NEVER approved
- `c8c8af1f` — second run, created via "Start Run" button, went through full analyze+design again

The "Start Run" button is visible when `project.status !== 'processing'` — and after the first run pauses for review, the project status is `review_pending`, so the button reappears.

### Fix Required (Multi-Part)

**Part A — Hide "Start Run" when review is pending**:

```typescript
// SpreadsheetProjectDetailPage.tsx:369
{canWrite && project.status !== 'processing' && project.status !== 'review_pending' && !runHook.isStreaming && (
  <Button ...>Start Run</Button>
)}
```

**Part B — Show only "Approve Plan" when in review_pending state**:

The `ExtractionPlanReview` component should be the primary action when a run is in `review_pending`. The "Start Run" button should be hidden or at least clearly secondary.

**Part C — Auto-load extraction plan on page load**:

When the user navigates to a project with a `review_pending` run, the extraction plan review should load automatically (currently only auto-surfaces from streaming events, not from direct page load).

```typescript
// On initial project load, check for review_pending runs
useEffect(() => {
  if (project?.status === 'review_pending') {
    // Find the review_pending run and surface its plan
    const reviewRun = runs.find(r => r.status === 'review_pending');
    if (reviewRun?.extractionPlan) {
      setReviewPlan(reviewRun.extractionPlan as SpreadsheetExtractionPlan);
      setReviewRunId(reviewRun.id);
    }
  }
}, [project, runs]);
```

### Files to Change

- `apps/web/src/pages/SpreadsheetProjectDetailPage.tsx` — Button visibility, auto-load review

---

## Issue 5: ExtractionPlanReview Shows Implementation Details (DuckDB references)

**Severity**: Low (UX Polish)
**Screenshot**: #5

### Root Cause

The `ExtractionPlanReview` component renders `plan.catalogMetadata.projectDescription` and `plan.catalogMetadata.dataQualityNotes` directly from the LLM output. The LLM was instructed in the design prompt to "generate DuckDB SQL" and mentions "Parquet tables for DuckDB" — these implementation details leak into the user-facing plan description.

**Evidence from screenshot #5**:
> "Extract historical financial statements... into analytics-ready Parquet tables for DuckDB."

### Fix Required (Multi-Part)

**Part A — Improve the design prompt**:

Remove technical implementation details from the prompt instructions that would leak into user-facing metadata. The prompt currently says:

```
The extraction plan will be used to generate DuckDB SQL that reads source files and writes Parquet output.
```

This should be rephrased to avoid mentioning DuckDB or Parquet in the context that leaks to catalog metadata.

**Part B — Clean up or hide implementation details in the UI**:

The `ExtractionPlanReview` component should either:
1. Filter out technical notes (containing "DuckDB", "Parquet", "SQL") from the displayed metadata
2. Show a simplified summary instead of raw LLM notes
3. Collapse the detailed notes behind an "Advanced" toggle

### Files to Change

- `apps/api/src/spreadsheet-agent/agent/nodes/design.ts` — Prompt refinement
- `apps/web/src/components/spreadsheet-agent/ExtractionPlanReview.tsx` — Hide/simplify details

---

## Issue 6: Phase Chips Show Phases as "Pending" When Agent Completes Instantly

**Severity**: Low (UX)
**Screenshot**: #2 (some phases pending despite completion), #6 (Ingest/Analyze/Design show pending icons)

### Root Cause

When the agent resumes after review approval, it skips ingest/analyze/design and goes directly to extract → validate → persist. These skipped phases never emit `phase_start` or `phase_complete` events, so their chips remain "pending" (grey/disabled).

On resume, the `useSpreadsheetRun` hook resets `events` to `[]` via `setEvents([])` in `startStream()`. So all phase status is lost from the first execution.

### Fix Required

**Option A**: On resume, pre-populate events from the first run's known completed phases. If `extractionPlan` exists in initial state (resume), emit synthetic `phase_complete` events for ingest, analyze, and design before the graph starts.

**Option B**: Don't reset events on resume — carry forward the events from the first streaming session.

### Files to Change

- `apps/api/src/spreadsheet-agent/agent/spreadsheet-agent-agent.service.ts` — Emit synthetic phase events on resume
- OR `apps/web/src/hooks/useSpreadsheetRun.ts` — Don't clear events on resume

---

## Issue 7: Project Status Stuck at "Processing" After Completion

**Severity**: High (Data)

### Root Cause

The persist node updates the project status:

```typescript
// persist.ts:60
await prisma.spreadsheetProject.update({
  where: { id: projectId },
  data: {
    status: projectStatus as any,  // 'ready', 'partial', or 'failed'
    tableCount: successfulResults.length,
    totalRows: BigInt(totalRows),
    totalSizeBytes: BigInt(totalSizeBytes),
  },
});
```

But when persist fails (due to Issue 3 — FK violation on invalid fileId), the catch block only sets `state.error` and returns, so the project status remains at `processing` (set during `claimRun`).

**Evidence from DB**:
```
Project status: processing  (should be 'ready' after completion)
Project tableCount: 0       (should be 23)
```

### Fix Required

This is a symptom of Issue 3. Once persist node works correctly (valid file IDs), the project status will be updated properly. Additionally, the agent service should update the project status to 'failed' if `finalState.error` is set.

---

## Issue 8: `claimRun` Allows Re-Claiming Approved Runs as "pending"

**Severity**: Medium (Logic Bug)

### Root Cause

The `approvePlan()` method sets the run status back to `pending`:

```typescript
// spreadsheet-agent.service.ts:721
data: {
  extractionPlanModified: (dto.modifications ?? null) as any,
  status: 'pending' as SpreadsheetRunStatus,
},
```

Then `claimRun()` transitions `pending → ingesting`:

```typescript
const result = await this.prisma.spreadsheetRun.updateMany({
  where: { id: runId, status: 'pending' },
  data: { status: 'ingesting', startedAt: new Date(), ... },
});
```

This **overwrites `startedAt`** with a new timestamp, losing the original start time from the first execution. It also re-sets the project status to `processing`.

### Fix Required

When approving a plan, transition to a different status (e.g., `extracting`) instead of `pending`. Or modify `claimRun` to handle the approved case differently — skip the `startedAt` overwrite if it already exists.

### Files to Change

- `apps/api/src/spreadsheet-agent/spreadsheet-agent.service.ts` — `approvePlan()` and `claimRun()`

---

## Issue 9: Timer Resets to 0:00 on Resume

**Severity**: Low (UX)

### Root Cause

When `startStream()` is called after approval, it resets `streamStartTime` to `Date.now()`:

```typescript
setStreamStartTime(Date.now());
```

This makes the timer show 0:04, 0:05 etc. during the extract/validate/persist phase, when the actual wall clock time since the user started the run is much longer (including the ~3.5 minutes of analyze+design).

### Fix Required

Either:
1. Don't reset `streamStartTime` if it was already set (carry forward from first stream)
2. Use the run's `startedAt` timestamp from the DB instead of a client-side timer

---

## Summary Table

| # | Issue | Severity | Root Cause Category |
|---|-------|----------|-------------------|
| 1 | Progress bar not shown during streaming | High | Frontend event parsing mismatch |
| 2 | Token count 0 on resume | Medium | State not carried across resume |
| 3 | Persist fails silently (0 tables created) | **Critical** | LLM hallucinates file IDs + silent error |
| 4 | "Start Run" creates new run instead of resume | High | Button visible during review_pending |
| 5 | DuckDB/Parquet details shown to user | Low | Prompt leaks implementation details |
| 6 | Phase chips show "pending" after instant completion | Low | Events reset on resume |
| 7 | Project status stuck at "processing" | High | Symptom of Issue 3 |
| 8 | claimRun overwrites startedAt on resume | Medium | Status transition design |
| 9 | Timer resets to 0:00 on resume | Low | Client-side timer reset |

---

## Recommended Fix Order

1. **Issue 3** (Critical) — Fix file ID handling in design/persist nodes. This unblocks the entire extraction pipeline.
2. **Issue 1** (High) — Fix progress bar. This is the most visible UX issue.
3. **Issue 4** (High) — Fix button visibility during review_pending. Prevents token waste.
4. **Issue 7** (High) — Will be fixed by Issue 3, plus add error state checking in agent service.
5. **Issue 8** (Medium) — Fix status transition for approved runs.
6. **Issue 2** (Medium) — Carry tokens across resume.
7. **Issue 6** (Low) — Emit synthetic phase events on resume.
8. **Issue 9** (Low) — Use run `startedAt` for timer.
9. **Issue 5** (Low) — Clean up prompt / UI for implementation details.
